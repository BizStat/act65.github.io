---
layout: post
title: Learning to Compose Neural Networks for Question Answering
category: summary
---

_This post is based around [Neural Module Networks](https://arxiv.org/pdf/1511.02799v3.pdf) and [Learning to Compose Neural Networks for Question Answering](https://arxiv.org/abs/1601.01705) by some of the CS guys at Berkeley._


# Problem setting

We want to answer a question about some other object (an image, a database, a text document). The question is received as natural language (represented as a string) and the answer is expected in natural language (also as a string). 

There seem to be two main approaches that (to some extent) work; semantic parsers that decompose questions into logical expressions and differentiable classifiers that filter information from the object through the lens of the question

> Rather than using logic to reason over truth values, the representations computed by our model remain entirely in the domain of visual features and attentions.

Parsing the questions is about mapping from one language to another. Normally we map to a logical language than can be interpreted by a computer program, but recently …? Another way to frame the problem is: generating a query to the data.

The filtering can be interpreted as [gating](http://papers.nips.cc/paper/6261-visual-question-answering-with-question-representation-update-qru.pdf), [predicting parameters](https://arxiv.org/abs/1306.0543) or [bilinear tensor operations](https://arxiv.org/abs/1606.01847). (Which are all similar in that they have a multiplicitave connection.)

Fundamentally it seems that we need to;

* parse the question,
* extract information from the object,
* ?


### Why is this problem hard/useful?

Applications? 



And difficulty?  $ = \mathcal O(?)$
This is really a combination of a few related but distinct problems? Grounding/localisation. Translation. Differentiable graph representations. ???


# How did they do it?

Definitions:

1. $w$, a world representation or object (e.g. if we are answering questions about images we might use a feature map, or the actual image??, from a CNN)
2. $x$, a question (represented as a string of words, as a one hot sequence of words??)
3. $y$, an answer (a distribution over words)
4. $z$, a network layout (represented as ??)

Split answering a question about an object into two tasks:

* $p(z \mid x)$, a distribution over likely parses (different ways to interpret/answer the question) (translating from their language to yours)
* $p_z(y \mid w)$, a distribution over likely answers given an architecture/parsing (query the input/object for the answer)

To achieve this, they need to;

* ground the question in the object,
* construct a new language to translate the question to, (this is the same as above?)
* efficiently evaluate and learn $p(z \mid x)$,
* ?

### Grounding

… ???

### A new language

So the semantics of their language are; 

* `find[i]`
* ..

??? and the syntax is … defined by the types.

With a series of modules of two types.

> <u>Attention</u> is a distribution over pixels or entities and <u>Labels</u> is a distribution over answers.

### Efficient translation

* type safety and type restrictions (only one `label`) to reduce search space.
* pre-made syntactic (as opposed to semantic) parser to generate likely 

(So their approach to make it learnable was to tighly constrain. Future work = make all learnable. Why bother? Differentiable systems allow; online learning, realtime? ... WHat are the benefits of making the parser differentiable?)

### Scoring and REINFORCE

A scoring function for ranking canidate architectures. $s(x) = a^T \sigma (Bh_q(x)+Cf(z_i)+d)$
Then normalise $s(x)$ with softmax to give $p(z_i \mid x)$. Now we can sample and train.
However we still need to learn the parameters for $s(x)$. So 

$$\nabla J(\theta_l) = \mathbb E[(\nabla log\; p(z\mid x ; \theta_l)) · log\; p(y \mid z,w; \theta_e)]$$


# Thoughts

(what does p(z \mid x) need to know? How does module f_i act. How does it effect a larger system when in position x. How do different modules interact. … We want a cheaper approximation that we can use to predict which graphs would be useful)


How is the problem best framed? Querying an object, versus gating information versus ???
To accurately and efficiently extract the information we want it seems intuitive that we need to know what we are looking for. However, it is not necessarily that simple. Ambiguity in the question may only become resolved after observing the context that it is meant.

> Rather than thinking of question answering as a problem of learning a single function to map from questions and images to answers, it is perhaps useful to think of it as a highly-multitask learning setting, where each problem instance is associated with a novel task, and the identity of that task is expressed only noisily in language.

Language is a tree/graph. If we ever want to be able to … we need to match its structure.

Common question in language design. What are the primitive functions required for universal computation. And what are the primitives suited to this application to make it efficient?
![relate]({{ site.baseurl }}/images/relate.png){: .center-image }

### What problem does it solve?

Reasoning solves a concrete computational problem. There is structure in each question. By using this we can learn faster and more accurately, and ??? 
More weight tying. 

### Why I think this paper is important

The title of section 2 pretty much sums up my interest in it: __Deep networks as functional programs__. This idea of differentiable programming has been floating around for a while, and there doesn’t seem to have been much significant progress on it (some links to related work?).

Since I read [Colah’s](http://colah.github.io/posts/2015-09-NN-Types-FP/) post on NNs and functional programming I have had the idea of .

Higher-level networks that can pass around other networks. Or in other words, we have first-class neural functions. I think this is what reasoning is, the ability to compose …

Interestingly, there are a couple of high level approaches to composing NNs. Distributed vs centralised.

We are reasoning (composing …???) with learned visual and linguistic representations! A language for ???.

Modular knowledge is transferable! (a name for carving nature at its joints)

### Issues, criticisms and things to keep in mind

A decent amount of simplification and cheating. 

* One word answers make things a lot easier.
* Pre-made parser for translation, CNN for CV and RNN for NLP.
* 

##### Expensive

Solving the problem of localisation/grounding. Softmax over pixels is probably a bad idea. Alternatives are ??, ??. [ref](https://arxiv.org/pdf/1511.03745v3.pdf)

Every module has access to the world state, $w$. So $\tilde w(h) = \sum_k h_kw_k$ is an expensive computation.

##### Scalability and batch learning. 

> Networks which have the same high-level structure but different instantiations of individual modules (for example what color is the cat? / `describe[color](find[cat])` and where is the truck? / `describe[where](find[truck]))` can be processed in the same batch, allowing efficient computation.

##### Syntactic parser

> These symbolic representations already determine the structure of the predicted networks, but not the identities of the modules that compose them. This final assignment of modules is fully determined by the structure of the parse.

Oh... so we are not actually generating a graph at all. Only filling it with the right modules. I guess that is because we used a syntactic parser, which captured the synatix. but we still need to fill in the semantics.


### Questions

* Type constraints. How do they enforce/use these?
* How is the distribution over pixels actually used?? Where do the features come from? Are they gated by this distribution?
* Where are the parameter arguments coming from? Continuous representations of a word/sentence? How do we know which word to `find[i]`?
* What happens if you remove some of the strict constraints on possible architectures? Having two `relate` fns, or ??.
* it feels like there should be more types/intermediate representations. What would they be. And/or how could we learn these? But what structure should they have and how can we regularise that into them?
* Learning to communicate. Each different protocol is a type? Learning to communicate is the same as learning a type system?

### Future work

* Would like a proof, which may be rather simple. That composing modules for question answering, is;
	* more efficient for answering questions. (requires less … memory, …
	* is easier to learn independent …s
	* better …
* I am hopeful that there is a nicer representation of graphs that will allow the backprop of gradients.  
* [differentiable graphs](https://tkipf.github.io/graph-convolutional-networks/). Although, more flexible languages to specify architectures means they will be harder to learn. A question I am interested in is: _How can we bias the architectures generated through the language we choose to represent them with?_ How is this related https://arxiv.org/pdf/1609.05600.pdf
* Interested to watch progress on [spatial-temporal](https://arxiv.org/abs/1612.01669) answering and [question asking](https://arxiv.org/abs/1611.08481)
* Relation to learning to communicate? _(Depending on the underlying structure, these messages passed between modules may be raw image features, attentions, or classification decisions; each module maps from specific input to output types.)_
* Less rigid/specified modules. Want to learn them.
* Local attention. Or some hierarchical representation of attention. As that shit is expensive.

### Problems to be solved

* Map what the question refers to within the object. (aka grounding of verbs and nouns??)
* ??
* ??

> the more general and challenging task of localizing entities based on arbitrary natural language expressions remains far from solved. ([Hu et al. 2016](https://arxiv.org/abs/1611.09978))

(can this be done using a generative model? why would you want to? . Generate an image from the language expression and minimise error, by changing your interpretation of the question, from what you are seeing?)


