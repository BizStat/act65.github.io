---
layout: post
title: How can we design/learn control systems to make GANs more stable?
category: problem
published: false
---

Can we borrow ideas from dynamical systems or controls to help control our system? The problem is that if our discriminator gets too good then ... and ...

$$
\begin{align}
&\textbf{GAN} \\
\mathcal{L}_{Forger} &= -log(1-fake) - log(real) \\
\mathcal{L}_{Curator} &= -log(fake) \\
\end{align}
$$

GANs are a pain in the ass to train (speaking from experience). Neural networks can be sensitive to initialisations and learning rates, and GANs add yet another layer to the tower of cards.

$$
\Delta_{Gen} = \eta_G \frac{\partial \mathcal L_{Forger}}{\partial \theta_{Gen}} \\
\Delta_{Dis} = \eta_D \frac{\partial \mathcal L_{Curator}}{\partial \theta_{Dis}} \\
$$

For example, this control scheme, inspired by the Lotka-Volterra system
![Lotka Volterra]({{ site.url }}/Images/LotkaVolterra.png)

$$
\frac{d\mathcal L_{Gen}}{dt} = \frac{\partial \mathcal L_{Forger}}{\partial \theta_{Gen}} \\
\Delta_{Dis} = \eta_D \frac{\partial \mathcal L_{Curator}}{\partial \theta_{Dis}} \\
$$

### Related ideas and resources

* see [this notebook]() for more thoughts and details.
* How can we __learn__ a control system?
* What loss are we actually minimizing? What is our true goal?
* Interesting problem, how to manage multiple learners/agents. Aka distributed optimisation?