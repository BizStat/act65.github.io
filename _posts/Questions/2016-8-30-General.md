---
layout: post
title: Is there a general theory of generalization?
category: problem
rating: 1
---

If I train my learning algorithm on dataset X, how will it generalise to some other domain/dataset Y? How tight will my classifier draw decision boundaries around X, and where does Y sit relative to these boundaries? If two datasets share S symmetries, or are within d distance, then I can generalise between them with P confidence? 

What I really want is a way to control how a network generalises -- where it generalises and how well. 

Related to;

* Manifold learning (??)
* [Adversarial examples](https://arxiv.org/abs/1502.02590)
* Transfer learning (??)