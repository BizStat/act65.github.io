---
layout: post
title: How can we design/learn control systems to make GANs more stable?
category: problem
rating: 1
---

Can we borrow ideas from dynamical systems or controls to help control our GAN? A DynaGAN? 

$$
\begin{align}
&\textbf{GAN} \\
\mathcal{L}_{Forger} &= -log(1-fake) - log(real) \\
\mathcal{L}_{Curator} &= -log(fake) \\
\end{align}
$$

GANs are a pain in the ass to train (speaking from experience).

$$
\Delta_{Gen} = \eta_G \frac{\partial \mathcal L_{Forger}}{\partial \theta_{Gen}} \\
\Delta_{Dis} = \eta_D \frac{\partial \mathcal L_{Curator}}{\partial \theta_{Dis}} \\
$$

For example, this control scheme, inspired by the Lotka-Volterra system
![Lotka Volterra]({{ site.url }}/Images/LotkaVolterra.png)

$$
\frac{d\mathcal L_{Gen}}{dt} = \frac{\partial \mathcal L_{Forger}}{\partial \theta_{Gen}} \\
\Delta_{Dis} = \eta_D \frac{\partial \mathcal L_{Curator}}{\partial \theta_{Dis}} \\
$$

### Related ideas and resources

* see [this notebook]() for more thoughts and details.
* How can we __learn__ a control system?
* What loss are we actually minimising? What is our true goal?
* Interesting problem, how to manage multiple learners/agents. Aka distributed optimisation?