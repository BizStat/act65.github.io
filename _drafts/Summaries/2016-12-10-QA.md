---
layout: post
title: Learning to Compose Neural Networks for Question Answering
category: summary
---

_This post is based around [Learning to Compose Neural Networks for Question Answering](https://arxiv.org/abs/1601.01705)._


### Problem setting

We want to answer a question about some other object (an image, a database, a text document). The question is received as natural language (represented as a string). 

Can also be framed as information retrieval? All the information we want is (or is not) contained in the object we are querying. We just need to know how to get it out.


For this we need to;

* query the object in an efficient manner,
* 

There are a few approaches to answering questions about an image. Which are … . A more interesting question, is whether you need the same amount of computation to answer each question. Are some questions harder to answer than others? How can we take advantage of this to be more efficient?

So we ??? is effectively learning to parse the question, and to map from the parsed question to a network layout.


### What problem does it solve?

There seem to be two main directions of work on this problem.

A fully differentiable combination of information. [1](http://papers.nips.cc/paper/6261-visual-question-answering-with-question-representation-update-qru.pdf), [2](https://arxiv.org/abs/1606.01847) This can be interpreted as gating, predicting parameters or bilinear tensor operations. (refs)

The problem with this work is that ??? Therefore …

### How did they do it?


Let;

1. $w$ be a world representation (e.g. if we are answering questions about images we might use the hidden representation from a CNN)
2. $x$ a question (a ??)
3. $y$ an answer (a distribution over words)
4. $z$ a network layout (represented as ??)



What other functions/modules would we want?
What other types make sense?

> <u>Attention</u> is a distribution over pixels or entities and <u>Labels</u> is a distribution over answers.


### Why I think this paper is important

The title of section 2 pretty much sums up my interest in it: __Deep networks as functional programs__. This idea of differentiable programming has been floating around for a while, and there doesn’t seem to have been much significant progress on it (some links to related work?).

Since I read [Colah’s](http://colah.github.io/posts/2015-09-NN-Types-FP/) post on NNs and functional programming I have had the idea of .

Higher-level networks that can pass around other networks. Or in other words, we have first-class neural functions. I think this is what reasoning is, the ability to compose …

Interestingly, there are a couple of high level approaches to composing NNs. Distributed vs centralised.


### Issues, criticisms and things to keep in mind

One word answers make things a lot easier.

Solving the problem of localisation/grounding. Softmax over pixels is probably a bad idea. Alternatives are ??, ??.


Every module has access to the world state, $w$. So $\tilde w(h) = \sum_k h_kw_k$ is an expensive computation.


### Questions


* Type constraints. How do they enforce these?
* Parameter prediction is just a multiplicative connection?
* relation to parsing?
* relation to reasoning?
* relation to multimodal language translation?
* How is the distribution over pixels actually used?? Where do the features come from? Are they gated by this distribution?
* where are the parameter arguments coming from?
* What happens if you remove some of the strict constraints on possible architectures? Having two `relate` fns, or ??.
* it feels like there should be more types/intermediate representations. What wouldd they be. And/or how could we learn these? But what structure should they have and how can we regularise that into them?


### Future work

* Would like a proof, which would be rather simple. That composing modules for question answering, is;
	* more efficient for answering questions. (requires less … memory, …
	* is easier to learn independent …s
* I am sure that there is a nice representation of graphs that will allow the backdrop of gradients.  
* [differentiable graphs](https://tkipf.github.io/graph-convolutional-networks/). Although, more flexible languages to specify architectures means they will be harder to learn. A question I am interested in is: _How can we bias the architectures generated through the language we choose to represent them with?_
* Interested to watch progress on [spatial-temporal](https://arxiv.org/abs/1612.01669) answering and [question asking](https://arxiv.org/abs/1611.08481)

##### Problems to be solved

* Map what the question refers to within the object. (aka grounding of verbs and nouns??)
* ??
* ??

> the more general and challenging task of localizing entities based on arbitrary natural language expressions remains far from solved. ([Hu et al. 2016](https://arxiv.org/abs/1611.09978))

(can this be done using a generative model? why would you want to? . Generate an image from the language expression and minimise error from what you are seeing?)


